debug: False
gpu: 1
seed: 0
tag: ${now:%Y-%m-%d-%H-%M-%S}
run_name: "train_expert_in_buffer_1e6_point_mass_cont_DDPG_RL_${train.train_cfg.mode}" 
# run_name: "train_${train.train_cfg.warmup_cfg.warmup_type})_point_mass_cont_DDPG_RL_${train.train_cfg.mode}" 

hydra:
  run:
    dir: outputs/${train.run_name}/${train.tag}

defaults:
  - /envs: gym_envs.yaml
  - _self_

wandb:
  entity: iam-lab
  group: drabe
  project: safety_rl_manip
  name: ${train.run_name}
wandb_resume_id: null

env_name: "point_mass_1D_cont_env-v0"
envs:
  point_mass_1D_cont_env-v0:
    doneType: 'all'
    return_type: 'reward'
    mode: ${train.train_cfg.mode}
    costType: 'max_ell_g'

train_cfg:
  warmupQ: False
  warmup_cfg:
    batch_size: 200
    num_epochs: 60
    warmup_q_lr: 1e-5
    warmup_pi_lr: 1e-3
    warmup_type: 'warmupQ_expert' # 'warmupQ_terminal_all_states', 'warmupQ_expert', 'warmup_pi'
    warmupQ_terminal_all_states:
      num_terminal_samples: 1e+4
    warmupQ_expert:
      num_mixed_terminal_samples: 1e+4
      expert_data_loc: '/home/saumyas/Projects/safe_control/HJR_manip/outputs/DoubleIntegrator/goto_goal_datasets/data_DoubleIntegrator_goto_goal_N_620.pkl'
      update_pi: True
      update_pi_type: 'maxQ' # 'expert', 'maxQ'
    warmup_pi:
      expert_data_loc: '/home/saumyas/Projects/safe_control/HJR_manip/outputs/DoubleIntegrator/goto_goal_datasets/data_DoubleIntegrator_goto_goal_N_620.pkl'
  add_expert_to_buffer: True
  expert_data_loc: '/home/saumyas/Projects/safe_control/HJR_manip/outputs/DoubleIntegrator/goto_goal_datasets/data_DoubleIntegrator_goto_goal_N_620.pkl'
  mode: 'lagrange' # RA, lagrange
  seed: ${train.seed}
  steps_per_epoch: 4000
  epochs: 200
  replay_size: 1e+6
  gamma: 0.99
  polyak: 0.995
  pi_lr: 1e-3 
  q_lr: 1e-3
  batch_size: 500
  start_steps: 10000
  update_after: 1000
  update_every: 50
  act_noise: 0.1
  num_test_episodes: 20
  max_ep_len: 200
  model_save_freq: 2
  plot_save_freq: 10
  save_top_k: 5
  ac_kwargs:
    hidden_sizes: [256,256]

