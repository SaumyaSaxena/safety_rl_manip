debug: False
gpu: 2
seed: 0
tag: ${now:%Y-%m-%d-%H-%M-%S}
run_name: "train_pickup1D_pick_object_DDPG_RL_return_${train.train_cfg.mode}" 

hydra:
  run:
    dir: outputs/${train.run_name}/${train.tag}

defaults:
  - /envs: gym_envs.yaml
  - _self_

wandb:
  entity: iam-lab
  group: drabe
  project: safety_rl_manip
  name: ${train.run_name}
  saver:
    upload: True
    save_top_k: 5
    save_freq: 10
wandb_resume_id: null

env_name: "pickup1D_env-v0"
envs:
  pickup1D_env-v0:
    doneType: 'all'
    return_type: 'reward'
    mode: ${train.train_cfg.mode}
    costType: 'max_ell_g'

train_cfg:
  warmupQ: False
  warmup_cfg: 
    warmup_type: 'terminal_all_states' # 'terminal_all_states', 'only_terminal_states', 'mixed_terminal_expert'
    num_terminal_samples: 1e+4
    num_mixed_terminal_samples: 1e+4
    expert_data_loc: '' 
    batch_size: 200
    num_epochs: 500
  mode: 'RA' # RA, lagrange
  seed: ${train.seed}
  steps_per_epoch: 4000
  epochs: 200
  replay_size: 1e+6
  gamma: 0.99
  polyak: 0.995
  pi_lr: 1e-3 
  q_lr: 1e-3
  batch_size: 500
  start_steps: 10000
  update_after: 1000
  update_every: 50
  act_noise: 0.1
  num_test_episodes: 20
  max_ep_len: 200
  model_save_freq: 2
  plot_save_freq: 10
  ac_kwargs:
    hidden_sizes: [256,256]