debug: False
gpu: 1
seed: 0
tag: ${now:%Y-%m-%d-%H-%M-%S}
# run_name: "train_expert_in_buffer_${train_cfg.expert_data_frac}_point_mass_cont_DDPG_RL_${train_cfg.mode}" 
run_name: "train_SAC_point_mass_${train_cfg.mode}"
# variant: ${train_cfg.warmup_cfg.warmup_type}_UpdatePiType_${train_cfg.warmup_cfg.warmupQ_expert.update_pi_type}
variant: 'gammaSch100'

hydra:
  run:
    dir: outputs/train/${run_name}/${tag}_${variant}
  job:
    chdir: True

defaults:
  - /envs: gym_envs.yaml
  - _self_

wandb:
  entity: iam-lab
  group: drabe/SAC
  project: safety_rl_manip
  name: ${run_name}_${variant}
wandb_resume_id: null

env_name: "point_mass_1D_cont_env-v0"
envs:
  point_mass_1D_cont_env-v0:
    doneType: 'all'
    return_type: 'reward'
    mode: ${train_cfg.mode}
    costType: 'max_ell_g'

train_cfg:
  algo_name: SAC
  warmup: False
  warmup_cfg:
    batch_size: 200
    num_epochs: 60
    warmup_q_lr: 1e-3
    warmup_pi_lr: 1e-3
    warmup_type: 'warmupQ_expert' # 'warmupQ_terminal_all_states', 'warmupQ_expert', 'warmup_pi'
    warmupQ_terminal_all_states:
      num_terminal_samples: 1e+4
    warmupQ_expert:
      num_mixed_terminal_samples: 1e+4
      expert_data_loc: '/home/saumyas/Projects/safe_control/HJR_manip/outputs/DoubleIntegrator/goto_goal_datasets/data_DoubleIntegrator_goto_goal_N_620.pkl'
      update_pi: True
      update_pi_type: 'expert' # 'expert', 'maxQ'
    warmup_pi:
      expert_data_loc: '/home/saumyas/Projects/safe_control/HJR_manip/outputs/DoubleIntegrator/goto_goal_datasets/data_DoubleIntegrator_goto_goal_N_620.pkl'
  add_expert_to_buffer: False
  expert_data_loc: '/home/saumyas/Projects/safe_control/HJR_manip/outputs/DoubleIntegrator/goto_goal_datasets/data_DoubleIntegrator_goto_goal_N_620.pkl'
  expert_data_frac: 0.75
  mode: 'RA' # RA, lagrange
  seed: ${seed}
  steps_per_epoch: 4000
  epochs: 200
  replay_size: 1e+6
  gamma: 0.99
  schedule_gamma: True
  gamma_warmup_epochs: 100
  polyak: 0.995
  pi_lr: 1e-3 
  q_lr: 1e-3
  AdamW:
    eps: 1.0e-8
    weight_decay: 0.01
  scheduler:
    sched: cosine
    # epochs are updated in code: epochs <- total_epochs - warmup - cooldown
    epochs: ${train_cfg.epochs}  # Total epochs to run (warmup + decay + cooldown)
    min_lr: 1.0e-5
    warmup_lr: 1.0e-4
    warmup_epochs: 10
    cooldown_epochs: 0
  alpha: 0.2
  batch_size: 100
  start_steps: 10000
  update_after: 1000
  update_every: 50
  num_test_episodes: 20
  max_ep_len: 1000
  model_save_freq: 2
  plot_save_freq: 10
  save_top_k: 5
  ac_kwargs:
    hidden_sizes: [256,256]

